# ğŸ”’ SecurePR

AI-powered security scanner for GitHub Pull Requests using OpenAI GPT-4.

[![Security Scan](https://github.com/jainilshah007/securePR/actions/workflows/security-scan.yml/badge.svg)](https://github.com/jainilshah007/securePR/actions/workflows/security-scan.yml)

## What It Does

SecurePR automatically scans your code changes for security vulnerabilities on every push. It uses GPT-4 to analyze git diffs and identify issues like:

- ğŸ”´ **SQL Injection** (CWE-89)
- ğŸ”´ **Command Injection** (CWE-78)
- ğŸŸ  **Hardcoded Secrets** (CWE-798)
- ğŸŸ  **XSS Vulnerabilities** (CWE-79)
- ğŸŸ  **Path Traversal** (CWE-22)
- ğŸŸ¡ **Insecure Randomness** (CWE-330)

## Quick Start

### 1. Add Your OpenAI API Key

Go to **Settings â†’ Secrets â†’ Actions** and add:
- Name: `OPENAI_API_KEY`
- Value: Your OpenAI API key

### 2. Create a Pull Request

The security scan runs automatically on every PR to `main`.

### 3. Check Results

View the scan results in the **Actions** tab. The workflow will fail if critical vulnerabilities are found.

---

## How I Built This

See [DEVELOPMENT.md](DEVELOPMENT.md) for detailed step-by-step build process.

**Summary:**
1. Basic GitHub Actions workflow setup
2. Commit info display with git commands
3. Python environment with OpenAI SDK
4. Security analyzer script with GPT-4
5. Prompt engineering for vulnerability detection
6. Markdown output formatting
7. Caching to reduce API costs
8. Confidence filtering to reduce false positives
9. PR trigger with base/head diff comparison

---

## Project Structure

```
securePR/
â”œâ”€â”€ .github/workflows/security-scan.yml   # GitHub Actions workflow
â”œâ”€â”€ scripts/analyze_security.py           # Security analyzer script
â”œâ”€â”€ test_vulnerable_code.py               # Test file with vulnerabilities
â”œâ”€â”€ DEVELOPMENT.md                        # Build process documentation
â””â”€â”€ README.md
```

## Configuration

| Setting | Default | Description |
|---------|---------|-------------|
| `CONFIDENCE_THRESHOLD` | 70 | Minimum confidence % to report |
| Model | `gpt-4o` | OpenAI model used |

## Example Output

```
ğŸ”’ SECURITY ANALYSIS RESULTS
==================================================
âš ï¸  Found 5 issue(s) (confidence â‰¥ 70%):

   ğŸ”´ Critical: 2
   ğŸŸ  High:     3

   Risk Level: CRITICAL
==================================================
ğŸ”´ [CRITICAL] SQL Injection (95% confidence)
File: app/database.py (Line 45)
Fix: Use parameterized queries.
```

